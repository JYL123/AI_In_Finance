"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", { value: true });
var doc_1 = require("../doc");
var globals_1 = require("../globals");
var tensor_util_1 = require("../tensor_util");
var util_1 = require("../util");
var axis_util_1 = require("./axis_util");
var binary_ops_1 = require("./binary_ops");
var operation_1 = require("./operation");
var tensor_ops_1 = require("./tensor_ops");
var Reduction;
(function (Reduction) {
    Reduction[Reduction["NONE"] = 0] = "NONE";
    Reduction[Reduction["MEAN"] = 1] = "MEAN";
    Reduction[Reduction["SUM"] = 2] = "SUM";
    Reduction[Reduction["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(Reduction = exports.Reduction || (exports.Reduction = {}));
var LossOps = (function () {
    function LossOps() {
    }
    LossOps.computeWeightedLoss = function (losses, weights, reduction) {
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $losses = tensor_util_1.convertToTensor(losses, 'losses', 'computeWeightedLoss');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'computeWeightedLoss');
        }
        var weightedLoss = ($weights == null) ? $losses : $losses.mul($weights);
        if (reduction === Reduction.NONE) {
            return weightedLoss;
        }
        if (reduction === Reduction.SUM) {
            return weightedLoss.sum();
        }
        if (reduction === Reduction.MEAN) {
            return ($weights == null) ? weightedLoss.mean() :
                weightedLoss.sum().div($weights.sum());
        }
        if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {
            if ($weights == null) {
                return weightedLoss.sum().div(tensor_ops_1.scalar($losses.size));
            }
            else {
                var broadcastedWeights = $weights.mul(tensor_ops_1.ones($losses.shape));
                var numNonZeros = broadcastedWeights.notEqual(tensor_ops_1.scalar(0)).sum().toFloat();
                return weightedLoss.sum().div(numNonZeros);
            }
        }
        throw Error("Unknown reduction: " + reduction);
    };
    LossOps.absoluteDifference = function (labels, predictions, weights, reduction) {
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'absoluteDifference');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'absoluteDifference');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'absoluteDifference');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in absoluteDifference: ');
        var losses = $labels.sub($predictions).abs();
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.meanSquaredError = function (labels, predictions, weights, reduction) {
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'meanSquaredError');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'meanSquaredError');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'meanSquaredError');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in meanSquaredError: ');
        var losses = $labels.squaredDifference($predictions);
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.cosineDistance = function (labels, predictions, axis, weights, reduction) {
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'cosineDistance');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'cosineDistance');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'cosineDistance');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');
        var one = tensor_ops_1.scalar(1);
        var losses = one.sub($labels.mul($predictions).sum(axis, true));
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.hingeLoss = function (labels, predictions, weights, reduction) {
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'hingeLoss');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'hingeLoss');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'hingeLoss');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');
        var one = tensor_ops_1.scalar(1);
        $labels = tensor_ops_1.scalar(2).mul($labels).sub(one);
        var losses = one.sub($labels.mul($predictions)).relu();
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.logLoss = function (labels, predictions, weights, epsilon, reduction) {
        if (epsilon === void 0) { epsilon = 1e-7; }
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'logLoss');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'logLoss');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'logLoss');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');
        var one = tensor_ops_1.scalar(1);
        var epsilonScalar = tensor_ops_1.scalar(epsilon);
        var losses = $labels.mul($predictions.add(epsilonScalar).log())
            .neg()
            .sub(one.sub($labels).mul(one.sub($predictions).add(epsilonScalar).log()));
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.huberLoss = function (labels, predictions, weights, delta, reduction) {
        if (delta === void 0) { delta = 1.0; }
        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'huberLoss');
        var $predictions = tensor_util_1.convertToTensor(predictions, 'predictions', 'huberLoss');
        var $weights = null;
        if (weights != null) {
            $weights = tensor_util_1.convertToTensor(weights, 'weights', 'huberLoss');
        }
        util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');
        var deltaScalar = tensor_ops_1.scalar(delta);
        var error = $predictions.sub($labels).abs();
        var quadratic = binary_ops_1.minimum(error, deltaScalar);
        var linear = error.sub(quadratic);
        var losses = tensor_ops_1.scalar(0.5).mul(quadratic.square()).add(deltaScalar.mul(linear));
        return LossOps.computeWeightedLoss(losses, $weights, reduction);
    };
    LossOps.softmaxCrossEntropy = function (labels, logits, dim) {
        if (dim === void 0) { dim = -1; }
        var $labels = tensor_util_1.convertToTensor(labels, 'labels', 'softmaxCrossEntropy');
        var $logits = tensor_util_1.convertToTensor(logits, 'logits', 'softmaxCrossEntropy');
        util_1.assertShapesMatch($labels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');
        if (dim === -1) {
            dim = $logits.rank - 1;
        }
        if (dim !== $logits.rank - 1) {
            throw Error("Softmax cross entropy along a non-last dimension is not yet " +
                ("supported. Labels / logits was rank " + $logits.rank + " ") +
                ("and dim was " + dim));
        }
        var customOp = globals_1.customGrad(function (labels, logits) {
            var predictedProbs = logits.softmax(dim);
            var costVector = tensor_ops_1.scalar(1e-5).add(predictedProbs).log().mul(labels).neg();
            var value = costVector.sum([dim]);
            var gradFunc = function (dy) {
                var dyShape = axis_util_1.expandShapeToKeepDim(dy.shape, [dim]);
                return [
                    dy.reshape(dyShape).mul(labels.toFloat().sub(predictedProbs)),
                    dy.reshape(dyShape).mul(predictedProbs.sub(labels.toFloat())),
                ];
            };
            return { value: value, gradFunc: gradFunc };
        });
        return customOp($labels, $logits);
    };
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "computeWeightedLoss", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "absoluteDifference", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "meanSquaredError", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "cosineDistance", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "hingeLoss", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "logLoss", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "huberLoss", null);
    __decorate([
        doc_1.doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' })
    ], LossOps, "softmaxCrossEntropy", null);
    return LossOps;
}());
exports.absoluteDifference = operation_1.op(LossOps.absoluteDifference);
exports.computeWeightedLoss = operation_1.op(LossOps.computeWeightedLoss);
exports.cosineDistance = operation_1.op(LossOps.cosineDistance);
exports.hingeLoss = operation_1.op(LossOps.hingeLoss);
exports.huberLoss = operation_1.op(LossOps.huberLoss);
exports.logLoss = operation_1.op(LossOps.logLoss);
exports.meanSquaredError = operation_1.op(LossOps.meanSquaredError);
exports.softmaxCrossEntropy = operation_1.op(LossOps.softmaxCrossEntropy);
//# sourceMappingURL=loss_ops.js.map